behaviors:
  Sheepherding:
    trainer_type: ppo
    hyperparameters:
      # 512 - 5120
      batch_size: 512
      # 2048 - 409600
      buffer_size: 2048
      learning_rate: 3.0e-4
      # 1e-4 - 1e-2 - increase for more random
      beta: 5.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 5
      learning_rate_schedule: linear
    network_settings:
      normalize: false
      hidden_units: 256
      num_layers: 2
    reward_signals:
      extrinsic:
        # 0.8 - 0.995 - discount factor
        gamma: 0.99
        strength: 1.0
    max_steps: 3000000
    time_horizon: 64
    summary_freq: 10000
    
#   testS:
#   batch_size: 1024, buffer_size: 5120, beta: 5.0e-3, gamma: 0.99 - good - 5/20
#   batch_size: 2048, buffer_size: 20480, beta: 5.0e-3, gamma: 0.95 - medium - 10/10
#   batch_size: 1024, buffer_size: 5120, beta: 5.0e-3, gamma: 0.95 - medium - 10/12
#   batch_size: 2048, buffer_size: 20480, beta: 5.0e-3, gamma: 0.95 - medium - 5/5
#   batch_size: 512, buffer_size: 2048, beta: 5.0e-3, gamma: 0.99 - great - 10/70
#   batch_size: 256, buffer_size: 1024, beta: 5.0e-3, gamma: 0.99 - good - 10/21
#   batch_size: 1024, buffer_size: 10240, beta: 5.0e-3, gamma: 0.99 - good - 10/20
#   batch_size: 512, buffer_size: 4096, beta: 5.0e-3, gamma: 0.99 - good - 10/26

#   testM: