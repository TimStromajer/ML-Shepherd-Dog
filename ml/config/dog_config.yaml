behaviors:
  Sheepherding:
    trainer_type: ppo
    hyperparameters:
      # 512 - 5120, 32 - 512 for discrete
      batch_size: 256   
      # 2048 - 409600   
      buffer_size: 4096
      # 1e-5 - 1e-3 - decrease if reward not increasing
      learning_rate: 3.0e-4
      # 1e-4 - 1e-2 - increase for more random
      beta: 0.01
      epsilon: 0.2
      lambd: 0.95
      # 3 - 10 - increse faster
      num_epoch: 5
      learning_rate_schedule: linear
    network_settings:
      normalize: false
      # increase for complex problems
      hidden_units: 512
      num_layers: 2
    reward_signals:
      extrinsic:
        # 0.8 - 0.995 - discount factor
        gamma: 0.99
        strength: 1.0
      curiosity:
        strength: 0.02
        gamma: 0.99
        network_settings:
          hidden_units: 256
        learning_rate: 0.0003
    max_steps: 10000000
    time_horizon: 64
    summary_freq: 10000
# environment_parameters:
  # sheep_number:
    # curriculum:    
      # - name: Lesson0
        # completion_criteria:
          # measure: reward
          # behavior: Sheepherding
          # signal_smoothing: true
          # min_lesson_length: 100
          # threshold: 8
          # require_reset: true
        # value: 1
      # - name: Lesson1
        # completion_criteria:
          # measure: reward
          # behavior: Sheepherding
          # signal_smoothing: true
          # min_lesson_length: 100
          # threshold: 8.1
          # require_reset: true
        # value: 2
      # - name: Lesson2
        # completion_criteria:
          # measure: reward
          # behavior: Sheepherding
          # signal_smoothing: true
          # min_lesson_length: 100
          # threshold: 8.2
          # require_reset: true
        # value: 3
      # - name: Lesson3
        # completion_criteria:
          # measure: reward
          # behavior: Sheepherding
          # signal_smoothing: true
          # min_lesson_length: 100
          # threshold: 8.3
          # require_reset: true
        # value: 4
      # - name: Lesson4
        # completion_criteria:
          # measure: reward
          # behavior: Sheepherding
          # signal_smoothing: true
          # min_lesson_length: 100
          # threshold: 8.4
          # require_reset: true
        # value: 5
      # - name: Lesson5
        # value: 6
    
# test2
#   batch_size: 512, buffer_size: 2048, beta: 5.0e-3, gamma: 0.99 - great - 500/-60
#   batch_size: 1024, buffer_size: 5120, beta: 5.0e-3, gamma: 0.99 - great - 500/-57
#   batch_size: 256, buffer_size: 2048, beta: 5.0e-3, gamma: 0.99 - great - 500/-66
#   batch_size: 2048, buffer_size: 8192, beta: 5.0e-3, gamma: 0.99 - great - 500/-64
#   batch_size: 1024, buffer_size: 10240, beta: 5.0e-3, gamma: 0.99 - great - 500/-63
#   batch_size: 1024, buffer_size: 2048, beta: 5.0e-3, gamma: 0.99 - great - 500/-63
#   batch_size: 1024, buffer_size: 5120, beta: 1.0e-4, gamma: 0.99 - great - 500/-44
#   batch_size: 1024, buffer_size: 5120, beta: 1.0e-4, gamma: 0.995 - great - 500/-54
#   batch_size: 1024, buffer_size: 5120, beta: 1.0e-4, gamma: 0.98 - great - 500/-56
    
#   testS:
#   batch_size: 1024, buffer_size: 5120, beta: 5.0e-3, gamma: 0.99 - good - 5/20
#   batch_size: 2048, buffer_size: 20480, beta: 5.0e-3, gamma: 0.95 - medium - 10/10
#   batch_size: 1024, buffer_size: 5120, beta: 5.0e-3, gamma: 0.95 - medium - 10/12
#   batch_size: 2048, buffer_size: 20480, beta: 5.0e-3, gamma: 0.95 - medium - 5/5
#   batch_size: 512, buffer_size: 2048, beta: 5.0e-3, gamma: 0.99 - great - 10/70
#   batch_size: 256, buffer_size: 1024, beta: 5.0e-3, gamma: 0.99 - good - 10/21
#   batch_size: 1024, buffer_size: 10240, beta: 5.0e-3, gamma: 0.99 - good - 10/20
#   batch_size: 512, buffer_size: 4096, beta: 5.0e-3, gamma: 0.99 - good - 10/26

#   testM:
#   batch_size: 512, buffer_size: 2048, beta: 5.0e-3, gamma: 0.99 - 30/27, 10/11


# max_steps = 1500 
# decision_period = 3, take action between decisions
# observations every 3 periods, actions every period